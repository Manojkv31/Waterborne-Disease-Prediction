{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "4bc664a5-aeb7-4089-a62e-8eba457707d6",
   "metadata": {},
   "source": [
    "\n",
    "# MALARIA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8bbca364-bc2b-46fc-8015-154b2c1461f8",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import seaborn as sp\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.preprocessing import LabelEncoder, OneHotEncoder\n",
    "from sklearn.model_selection import KFold\n",
    "from imblearn.over_sampling import RandomOverSampler\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.metrics import roc_curve\n",
    "from sklearn.model_selection import train_test_split\n",
    "import pandas as pd\n",
    "from sklearn.utils import resample\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "from sklearn.svm import SVC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2cad1a96-aeeb-489d-a97b-02effe6b88a5",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "malaria = pd.read_csv('Dataset/malaria_dataset.csv')\n",
    "malaria.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cfdade73-e8a8-438f-a3ba-9fe002af5ca1",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "malaria.drop(['Unnamed: 0'], axis=1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3aedc3c7-75be-443c-a6cc-76de27311b78",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "malaria.drop_duplicates()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ac7d0e64-7e44-41d8-9143-ec0c350fda3b",
   "metadata": {},
   "source": [
    "## DATA CLEANING"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "43e6b35d-75d8-42d4-b4a9-c40bfd12e84d",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "malaria['DISTRICT'].fillna(malaria['DISTRICT'].mode()[0], inplace = True)\n",
    "malaria['AGE'].fillna(malaria['AGE'].median(), inplace = True)\n",
    "malaria['REPORT_VERIFIED'].fillna(malaria['REPORT_VERIFIED'].mode()[0], inplace = True)\n",
    "malaria['TEHSIL'].fillna(malaria['TEHSIL'].mode()[0], inplace = True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b3d5e966-6abc-4874-9908-8febe5e63528",
   "metadata": {},
   "source": [
    "## DATA BALANCING"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2bfb356c-528b-432d-99aa-4860e4fd0ed8",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "#Class Distribution\n",
    "class_counts_typ = malaria['RESULT_TEXT'].value_counts()\n",
    "\n",
    "class_distribution_typ =class_counts_typ / len(malaria) *100\n",
    "\n",
    "print(class_distribution_typ)\n",
    "\n",
    "#plot a bar graph\n",
    "value = malaria['RESULT_TEXT'].value_counts()\n",
    "\n",
    "plt.bar(value.index, value.values)\n",
    "\n",
    "plt.title('RESULT_TEXT')\n",
    "plt.xlabel('Result')\n",
    "plt.ylabel('Count')\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "439ad240-c380-4077-b87e-03f4f205d143",
   "metadata": {},
   "outputs": [],
   "source": [
    "from imblearn.under_sampling import RandomUnderSampler\n",
    "\n",
    "# Separate features and target variable\n",
    "x = malaria.drop('RESULT_TEXT', axis=1)\n",
    "y = malaria['RESULT_TEXT']\n",
    "\n",
    "# Undersample the majority class using RandomUnderSampler\n",
    "rus = RandomUnderSampler(random_state=42)\n",
    "x_resampled, y_resampled = rus.fit_resample(x, y)\n",
    "\n",
    "# Concatenate the features and target into balanced dataset\n",
    "balanced_data = pd.concat([x_resampled, y_resampled], axis=1)\n",
    "\n",
    "balanced_data.to_csv('new_copy2/Balanced_Malaria.csv', index = False)\n",
    "\n",
    "Balanced_malaria = pd.read_csv('new_copy2/Balanced_Malaria.csv')\n",
    "\n",
    "#Class Distribution\n",
    "class_counts_typ = Balanced_malaria['RESULT_TEXT'].value_counts()\n",
    "\n",
    "class_distribution_typ =class_counts_typ / len(Balanced_malaria) *100\n",
    "\n",
    "print(class_distribution_typ)\n",
    "\n",
    "#plot a bar graph\n",
    "value = Balanced_malaria['RESULT_TEXT'].value_counts()\n",
    "\n",
    "plt.bar(value.index, value.values)\n",
    "\n",
    "plt.title('RESULT_TEXT')\n",
    "plt.xlabel('Result')\n",
    "plt.ylabel('Count')\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3b6dd810-e183-4390-8ef4-ddc8e36bf488",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "Balanced_malaria.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "437c5c45-c8b5-4e7e-aaf4-7cebe711ec61",
   "metadata": {},
   "source": [
    "## DATA TRANSFORMATION"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0eec5e9f-0e4c-4290-b3e2-032e6711e6d2",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "le = LabelEncoder()\n",
    "Balanced_malaria[\"MRNO_encoded\"] = le.fit_transform(Balanced_malaria[\"MRNO\"])\n",
    "Balanced_malaria[\"RESULT_VALUE_encoded\"] = le.fit_transform(Balanced_malaria[\"RESULT_VALUE\"])\n",
    "Balanced_malaria[\"GENDER_encoded\"] = le.fit_transform(Balanced_malaria[\"GENDER\"])\n",
    "Balanced_malaria[\"REPORT_VERIFIED_encoded\"] = le.fit_transform(Balanced_malaria[\"REPORT_VERIFIED\"])\n",
    "Balanced_malaria[\"RESULT_TEXT_encoded\"] = le.fit_transform(Balanced_malaria[\"RESULT_TEXT\"])\n",
    "# One-hot encode District and Tehsil\n",
    "ohe = OneHotEncoder(sparse=False)\n",
    "district_tehsil_encoded = ohe.fit_transform(Balanced_malaria[[\"DISTRICT\", \"TEHSIL\"]])\n",
    "district_tehsil_encoded_df = pd.DataFrame(district_tehsil_encoded, columns=ohe.get_feature_names_out([\"DISTRICT\", \"TEHSIL\"]))\n",
    "\n",
    "# Combine the encoded columns with the original dataset\n",
    "new_df = pd.concat([Balanced_malaria[\"MRNO_encoded\"], district_tehsil_encoded_df], axis=1)\n",
    "new_df[\"AGE\"] = Balanced_malaria[\"AGE\"]\n",
    "new_df[\"RESULT_TEXT\"] = Balanced_malaria[\"RESULT_TEXT_encoded\"]\n",
    "new_df[\"GENDER\"] = Balanced_malaria[\"GENDER_encoded\"]\n",
    "new_df[\"RESULT_VALUE\"] = Balanced_malaria[\"RESULT_VALUE_encoded\"]\n",
    "new_df[\"REPORT_VERIFIED\"] = Balanced_malaria[\"REPORT_VERIFIED_encoded\"]\n",
    "new_df[\"CPT_ID\"] = Balanced_malaria[\"CPT_ID\"]\n",
    "new_df[\"CPT_ID.1\"] = Balanced_malaria[\"CPT_ID.1\"]\n",
    "# Save the new dataframe to a new CSV file\n",
    "new_df.to_csv('new_copy2/New_Malaria.csv', index = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3b3bb089-77d7-403a-8a16-374fbeb174a6",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "print(Balanced_malaria['MRNO_encoded'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "02956f3e-1c3b-467d-9003-636b91f7f20e",
   "metadata": {},
   "source": [
    "## DATA NORMALISATION"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c98cd66e-9f8d-488d-bbd1-ffb443db5bf1",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "value = Balanced_malaria['AGE'].value_counts()\n",
    "\n",
    "plt.bar(value.index, value.values)\n",
    "\n",
    "plt.title('AGE')\n",
    "plt.xlabel('Age')\n",
    "plt.ylabel('Count')\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "89c5bace-4616-4464-afe1-c71c8a7f9f53",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "Transformed_malaria = pd.read_csv('new_copy2/New_Malaria.csv', low_memory = False)\n",
    "# Column to be normalized\n",
    "column = ['AGE']\n",
    "\n",
    "Transformed_malaria[column] = (Transformed_malaria[column] - Transformed_malaria[column].mean()) / Transformed_malaria[column].std()\n",
    "\n",
    "# New .csv file with normalized data\n",
    "Transformed_malaria.to_csv('new_copy2/Normalized_Malaria.csv', index = False)# Column to be normalized\n",
    "column = ['AGE']\n",
    "\n",
    "Transformed_malaria[column] = (Transformed_malaria[column] - Transformed_malaria[column].mean()) / Transformed_malaria[column].std()\n",
    "\n",
    "# New .csv file with normalized data\n",
    "Transformed_malaria.to_csv('new_copy2/Normalized_Malaria.csv', index = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6fa27bd6-0652-4a94-a0ec-a55086d0fa28",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "Normal_malaria = pd.read_csv('new_copy2/Normalized_Malaria.csv', low_memory = False)\n",
    "print(Normal_malaria['AGE'].head())\n",
    "\n",
    "value = Normal_malaria['AGE'].value_counts()\n",
    "\n",
    "plt.bar(value.index, value.values)\n",
    "\n",
    "plt.title('AGE')\n",
    "plt.xlabel('Age')\n",
    "plt.ylabel('Count')\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "860cb2db-93f8-4ca0-9d5a-0ccb3ab624d7",
   "metadata": {},
   "source": [
    "## RANDOM FOREST FEATURE SELECTION"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "495c1d04-9276-47e5-b6f4-fd0afb307215",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Drop rows with missing data\n",
    "Normal_malaria.dropna(inplace=True)\n",
    "\n",
    "# Split the data into feature matrix X and target vector y\n",
    "X = Normal_malaria.drop('RESULT_TEXT', axis=1)\n",
    "y = Normal_malaria['RESULT_TEXT']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8dbaebd6-d7fa-449d-b9aa-9b7389d5009e",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Use random forest to select the most important features\n",
    "rfc = RandomForestClassifier(n_estimators=100)\n",
    "rfc.fit(X, y)\n",
    "importance = rfc.feature_importances_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6ea6c9cc-e981-4957-9ee7-6697a3d4057f",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Create a list of (feature name, importance) tuples and sort by importance\n",
    "features = list(zip(X.columns, importance))\n",
    "features.sort(key=lambda x: x[1], reverse=True)\n",
    "\n",
    "# Print the sorted list of feature importances\n",
    "for f in features:\n",
    "    print(f)\n",
    "\n",
    "\n",
    "# Select the top k features\n",
    "k = 7\n",
    "top_features = [f[0] for f in features[:k]]\n",
    "for f in top_features:\n",
    "    print(f)\n",
    "X = X[top_features]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "09e2a8c0-d33e-4de3-8c08-8eca36968dd4",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "plt.title(\"Histogram for Feature selection importance\");\n",
    "plt.barh([x[0] for x in top_features],[x[1] for x in top_features])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "946a59e1-a432-431b-8387-45b94a32ef85",
   "metadata": {},
   "source": [
    "## RANDOM FOREST CLASSIFIER"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a45e5bee-65b0-43a0-a84d-94c638e0eed8",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Train and evaluate the model using KFold\n",
    "kf = KFold(n_splits=10, shuffle=True, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2c332ff2-82a1-4a4b-8523-d28a395897ee",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "accuracy_scores = []\n",
    "y_preds=[]\n",
    "y_tests=[]\n",
    "for train_index, test_index in kf.split(X):\n",
    "    # Split data into train and test sets for this fold\n",
    "    X_train, X_test = X.iloc[train_index], X.iloc[test_index]\n",
    "    y_train, y_test = y.iloc[train_index], y.iloc[test_index]\n",
    "\n",
    "    # Create and train the random forest classifier\n",
    "    rfc = RandomForestClassifier(n_estimators=100)\n",
    "    rfc.fit(X_train, y_train)\n",
    "\n",
    "    # Make predictions on the test set and calculate accuracy\n",
    "    y_pred = rfc.predict(X_test)\n",
    "    y_preds.extend(y_pred)\n",
    "    y_tests.extend(y_test)\n",
    "    accuracy = accuracy_score(y_test, y_pred)\n",
    "\n",
    "    # Add accuracy score to list\n",
    "    accuracy_scores.append(accuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4c8a9be7-903e-4bed-a7ca-f2495f725124",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Compute and print the mean accuracy score and standard deviation\n",
    "print(\"Accuracy- Random forest classifier: %0.2f (+/- %0.2f)\" % (np.mean(accuracy_scores), np.std(accuracy_scores) * 2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "99c6aa49-4c66-4e52-a004-5f771b32611b",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Assuming the true and predicted labels are stored in y_true and y_pred respectively\n",
    "cm = confusion_matrix(y_tests, y_preds)\n",
    "\n",
    "# Create a heatmap of the confusion matrix using Seaborn\n",
    "sp.heatmap(cm, annot=True, cmap=\"Blues\", fmt = 'd')\n",
    "\n",
    "# Add axis labels and a title\n",
    "plt.xlabel(\"Predicted labels\")\n",
    "plt.ylabel(\"True labels\")\n",
    "plt.title(\"Confusion Matrix for Random forest\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "82b3b7d1-bafd-470b-88f5-a5bec68421b6",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# y_true: true labels, y_pred_prob: predicted probabilities\n",
    "fpr, tpr, thresholds = roc_curve(y_tests, y_preds)\n",
    "\n",
    "# plot ROC curve\n",
    "plt.plot(fpr, tpr)\n",
    "plt.plot([0, 1], [0, 1], linestyle='--')  # plot random curve\n",
    "plt.xlabel('False Positive Rate')\n",
    "plt.ylabel('True Positive Rate')\n",
    "plt.title('ROC Curve for Random Forest')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "57f984c0-4149-4e2a-83c7-b42b7979f56b",
   "metadata": {},
   "source": [
    "## KNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b96c42e7-f7b0-46cf-aac4-5b9cffe6ae6a",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "knn = KNeighborsClassifier(n_neighbors=5)\n",
    "\n",
    "kfold = KFold(n_splits=10, shuffle=True, random_state=42)\n",
    "accuracy_scores = []\n",
    "# Perform K-fold cross-validation and evaluate the model's performance\n",
    "y_true = []\n",
    "y_pred = []\n",
    "for train_idx, test_idx in kfold.split(X):\n",
    "    X_train, X_test = X.iloc[train_idx], X.iloc[test_idx]\n",
    "    y_train, y_test = y.iloc[train_idx], y.iloc[test_idx]\n",
    "    knn.fit(X_train, y_train)\n",
    "    y_true.extend(y_test)\n",
    "    y_pred.extend(knn.predict(X_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "62d876a2-7ce8-47e0-9571-16551acc8cfa",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "accuracy = accuracy_score(y_true, y_pred)\n",
    "# Add accuracy score to list\n",
    "accuracy_scores.append(accuracy)\n",
    "# Compute and print the mean accuracy score and standard deviation\n",
    "print(\"Accuracy- KNN: %0.2f (+/- %0.2f)\" % (np.mean(accuracy_scores), np.std(accuracy_scores) * 2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "22a84bfe-a589-468b-975d-819a226380f7",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Assuming the true and predicted labels are stored in y_true and y_pred respectively\n",
    "cm = confusion_matrix(y_true, y_pred)\n",
    "# Create a heatmap of the confusion matrix using Seaborn\n",
    "sp.heatmap(cm, annot=True, cmap=\"Blues\", fmt=\"d\")\n",
    "\n",
    "# Add axis labels and a title\n",
    "plt.xlabel(\"Predicted labels\")\n",
    "plt.ylabel(\"True labels\")\n",
    "plt.title(\"Confusion Matrix for KNN\")\n",
    "\n",
    "# Show the plot\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "54bb9639-64b0-4bbd-b64e-95ad8005da63",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# y_true: true labels, y_pred_prob: predicted probabilities\n",
    "fpr, tpr, thresholds = roc_curve(y_true, y_pred)\n",
    "\n",
    "# plot ROC curve\n",
    "plt.plot(fpr, tpr)\n",
    "plt.plot([0, 1], [0, 1], linestyle='--')  # plot random curve\n",
    "plt.xlabel('False Positive Rate')\n",
    "plt.ylabel('True Positive Rate')\n",
    "plt.title('ROC Curve for KNN')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "35a38bd2-1ff4-4860-a7d5-b63b059369a0",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# y_true: true labels, y_pred_prob: predicted probabilities\n",
    "fpr, tpr, thresholds = roc_curve(y_true, y_pred)\n",
    "\n",
    "# plot ROC curve\n",
    "plt.plot(fpr, tpr)\n",
    "plt.plot([0, 1], [0, 1], linestyle='--')  # plot random curve\n",
    "plt.xlabel('False Positive Rate')\n",
    "plt.ylabel('True Positive Rate')\n",
    "plt.title('ROC Curve for KNN')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8e8d1586-a1f9-4648-9a1a-f9d843ca4c1e",
   "metadata": {},
   "source": [
    "## DECISION TREE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "128f16e3-fbac-472b-9e6c-e9de2e18458a",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Initialize an empty list to store cross-validation scores\n",
    "scores = []\n",
    "y_pred=[]\n",
    "y_preds=[]\n",
    "y_tests=[]\n",
    "# Iterate over the splits of the data and train/test the model\n",
    "for train_index, test_index in kf.split(X):\n",
    "    # Split the data into training and testing sets for this fold\n",
    "    X_train, X_test = X.iloc[train_index], X.iloc[test_index]\n",
    "    y_train, y_test = y.iloc[train_index], y.iloc[test_index]\n",
    "    \n",
    "    # Train the decision tree classifier\n",
    "    dt = DecisionTreeClassifier(random_state=42)\n",
    "    dt.fit(X_train, y_train)\n",
    "    \n",
    "    # Evaluate the model's performance on the test set for this fold and store the score\n",
    "    y_pred = dt.predict(X_test)\n",
    "    y_preds.extend(y_pred)\n",
    "    y_tests.extend(y_test)\n",
    "    score = accuracy_score(y_test, y_pred)\n",
    "    scores.append(score)\n",
    "\n",
    "# Calculate the mean and standard deviation of the cross-validation scores\n",
    "mean_score = sum(scores) / len(scores)\n",
    "std_dev = np.std(scores)\n",
    "\n",
    "# Print the results\n",
    "print(\"Accuracy-Decision tree: %0.2f (+/- %0.2f)\" % (mean_score, std_dev * 2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b305c28f-2306-4451-89b7-05c3531cf307",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Assuming the true and predicted labels are stored in y_true and y_pred respectively\n",
    "cm = confusion_matrix(y_tests, y_preds)\n",
    "np.set_printoptions(precision=3, suppress=True)\n",
    "# Create a heatmap of the confusion matrix using Seaborn\n",
    "sp.heatmap(cm, annot=True, cmap=\"Blues\",fmt=\"d\")\n",
    "\n",
    "# Add axis labels and a title\n",
    "plt.xlabel(\"Predicted labels\")\n",
    "plt.ylabel(\"True labels\")\n",
    "plt.title(\"Confusion Matrix for Decision tree\")\n",
    "\n",
    "# Show the plot\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6ad662cb-144f-4cf7-91b9-6d765392d764",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# y_true: true labels, y_pred_prob: predicted probabilities\n",
    "fpr, tpr, thresholds = roc_curve(y_tests, y_preds)\n",
    "\n",
    "# plot ROC curve\n",
    "plt.plot(fpr, tpr)\n",
    "plt.plot([0, 1], [0, 1], linestyle='--')  # plot random curve\n",
    "plt.xlabel('False Positive Rate')\n",
    "plt.ylabel('True Positive Rate')\n",
    "plt.title('ROC Curve for Decision tree')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bd30ee69",
   "metadata": {},
   "source": [
    "## Logistic Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8a3247d5-f614-4bee-bb27-14ebe7bc67e7",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Perform 10-fold cross validation using KFold method\n",
    "kf = KFold(n_splits=10, shuffle=True, random_state=42)\n",
    "lr = LogisticRegression(C=1)\n",
    "scores = []\n",
    "y_preds = []\n",
    "y_true = []\n",
    "for train_index, test_index in kf.split(X):\n",
    "    X_train, X_test = X.iloc[train_index], X.iloc[test_index]\n",
    "    y_train, y_test = y.iloc[train_index], y.iloc[test_index]\n",
    "    lr.fit(X_train, y_train)\n",
    "    y_pred = lr.predict(X_test)\n",
    "    y_preds.extend(y_pred)\n",
    "    y_true.extend(y_test)\n",
    "    scores.append(lr.score(X_test, y_test))\n",
    "\n",
    "# Calculate and print the cross-validation accuracy\n",
    "print(\"Accuracy- Logistic Regression: %0.2f (+/- %0.2f)\" % (np.mean(scores), np.std(scores) * 2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2114d3fc-ceed-4bc9-a364-859e94f26708",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from imblearn.combine import SMOTEENN\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.model_selection import cross_val_score, KFold\n",
    "from sklearn.metrics import classification_report, confusion_matrix\n",
    "\n",
    "\n",
    "# Define the hybrid sampling method\n",
    "smote_enn = SMOTEENN(random_state=42)\n",
    "scores = []\n",
    "# Define the logistic regression classifier\n",
    "logreg = LogisticRegression(random_state=42)\n",
    "\n",
    "# Define the KFold cross-validator\n",
    "kfold = KFold(n_splits=10, shuffle=True, random_state=42)\n",
    "\n",
    "# Perform K-fold cross-validation and evaluate the model's performance\n",
    "for train_idx, test_idx in kfold.split(X):\n",
    "    X_train, X_test = X.iloc[train_idx], X.iloc[test_idx]\n",
    "    y_train, y_test = y.iloc[train_idx], y.iloc[test_idx]\n",
    "    \n",
    "    # Apply the hybrid sampling method on the training set only\n",
    "    X_resampled, y_resampled = smote_enn.fit_resample(X_train, y_train)\n",
    "    \n",
    "    # Fit the logistic regression model on the resampled training set\n",
    "    logreg.fit(X_resampled, y_resampled)\n",
    "    \n",
    "    # Make predictions on the test set\n",
    "    y_pred = logreg.predict(X_test)\n",
    "    \n",
    "    # Evaluate the model's performance on the test set\n",
    "    y_preds.extend(y_pred)\n",
    "    y_true.extend(y_test)\n",
    "    scores.append(lr.score(X_test, y_test))\n",
    "    \n",
    "    # Calculate the cross-validation accuracy\n",
    "    #scores = cross_val_score(logreg, X_resampled, y_resampled, cv=kfold)\n",
    "\n",
    "print(\"Cross-validation accuracy: %0.2f (+/- %0.2f)\\n\" % (np.mean(scores), np.std(scores) * 2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4c02e3a0-cdd7-4752-9933-b24bc3a92b94",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Assuming the true and predicted labels are stored in y_true and y_pred respectively\n",
    "cm = confusion_matrix(y_true, y_preds)\n",
    "np.set_printoptions(precision=3, suppress=True)\n",
    "# Create a heatmap of the confusion matrix using Seaborn\n",
    "sp.heatmap(cm, annot=True, cmap=\"Blues\",fmt=\"d\")\n",
    "\n",
    "# Add axis labels and a title\n",
    "plt.xlabel(\"Predicted labels\")\n",
    "plt.ylabel(\"True labels\")\n",
    "plt.title(\"Confusion Matrix for Logistic Regression\")\n",
    "\n",
    "# Show the plot\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "40159075-41ef-459d-b919-2e51d395008c",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# y_true: true labels, y_pred_prob: predicted probabilities\n",
    "fpr, tpr, thresholds = roc_curve(y_test, y_pred)\n",
    "\n",
    "# plot ROC curve\n",
    "plt.plot(fpr, tpr)\n",
    "plt.plot([0, 1], [0, 1], linestyle='--')  # plot random curve\n",
    "plt.xlabel('False Positive Rate')\n",
    "plt.ylabel('True Positive Rate')\n",
    "plt.title('ROC Curve for Logisitic Regression')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6680364d",
   "metadata": {},
   "source": [
    "## SVM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "69ea8fb0-2d8e-45ad-989d-af3d1e03c2ba",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "y_pred=[]\n",
    "y_preds=[]\n",
    "y_true=[]\n",
    "# Define the desired sample size for the reduced dataset\n",
    "sample_size = 5000\n",
    "\n",
    "# Initialize SVM classifier with default hyperparameters\n",
    "svm = SVC()\n",
    "\n",
    "# Use stratified k-fold cross-validation to evaluate classifier performance\n",
    "skf = StratifiedKFold(n_splits=10, random_state=42, shuffle=True)\n",
    "scores = []\n",
    "\n",
    "# Loop over each fold and perform stratified sampling on the training set\n",
    "for train_index, test_index in skf.split(X,y):\n",
    "    \n",
    "    X_train, X_test = X.iloc[train_index], X.iloc[test_index]\n",
    "    y_train, y_test = y.iloc[train_index], y.iloc[test_index]\n",
    "    \n",
    "    # Use stratified sampling to select the desired number of samples from each class\n",
    "    X_sampled, y_sampled = resample(X_train, y_train, n_samples=sample_size, stratify=y_train, random_state=42)\n",
    "\n",
    "    # Fit SVM classifier on the reduced dataset and evaluate performance on the test set\n",
    "    svm.fit(X_sampled, y_sampled)\n",
    "    y_pred = svm.predict(X_test)\n",
    "    y_preds.extend(y_pred)\n",
    "    y_true.extend(y_test)\n",
    "    scores.append(svm.score(X_test,y_test))\n",
    "\n",
    "# Print the average classification accuracy over all folds\n",
    "print(\"Accuracy- SVM: {:.2f}\".format(sum(scores)/len(scores)))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "939f5403-e0da-49a7-90d4-8fcd9fb39511",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Assuming the true and predicted labels are stored in y_true and y_pred respectively\n",
    "cm = confusion_matrix(y_true, y_preds)\n",
    "np.set_printoptions(precision=3, suppress=True)\n",
    "# Create a heatmap of the confusion matrix using Seaborn\n",
    "sp.heatmap(cm, annot=True, cmap=\"Blues\",fmt=\"d\")\n",
    "\n",
    "# Add axis labels and a title\n",
    "plt.xlabel(\"Predicted labels\")\n",
    "plt.ylabel(\"True labels\")\n",
    "plt.title(\"Confusion Matrix for SVM \")\n",
    "\n",
    "# Show the plot\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "add6073e-c6ac-4ba6-b00c-fc64ca864c50",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# y_true: true labels, y_pred_prob: predicted probabilities\n",
    "fpr, tpr, thresholds = roc_curve(y_test, y_pred)\n",
    "\n",
    "# plot ROC curve\n",
    "plt.plot(fpr, tpr)\n",
    "plt.plot([0, 1], [0, 1], linestyle='--')  # plot random curve\n",
    "plt.xlabel('False Positive Rate')\n",
    "plt.ylabel('True Positive Rate')\n",
    "plt.title('ROC Curve for SVM')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a1293b43-74a1-49b7-b521-20be14eb9124",
   "metadata": {},
   "source": [
    "## ENSEMBLE"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "13100c40",
   "metadata": {},
   "source": [
    "### Voting Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d39a1d9a-3517-4765-9a33-d2acc914d82e",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from sklearn.model_selection import KFold\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.ensemble import RandomForestClassifier, VotingClassifier\n",
    "\n",
    "# Set up KFold cross-validation\n",
    "kf = KFold(n_splits=10, shuffle=True, random_state=42)\n",
    "\n",
    "# Initialize empty lists to store scores and predictions\n",
    "scores = []\n",
    "y_preds = []\n",
    "y_tests = []\n",
    "\n",
    "# Train the models and ensemble them\n",
    "rf = RandomForestClassifier(n_estimators=100)\n",
    "dt = DecisionTreeClassifier(random_state=42)\n",
    "lr=LogisticRegression(C=1)\n",
    "ensemble = VotingClassifier(estimators=[('rf', rf), ('dt', dt), ('lr', lr)], voting='hard')\n",
    "\n",
    "# Loop over the splits of the data and train/test the models\n",
    "for train_index, test_index in kf.split(X):\n",
    "    # Split the data into training and testing sets for this fold\n",
    "    X_train, X_test = X.iloc[train_index], X.iloc[test_index]\n",
    "    y_train, y_test = y.iloc[train_index], y.iloc[test_index]\n",
    "\n",
    "    # Fit the models to the training data for this fold\n",
    "    rf.fit(X_train, y_train)\n",
    "    dt.fit(X_train, y_train)\n",
    "    lr.fit(X_train, y_train)\n",
    "\n",
    "    # Fit the ensemble model to the training data for this fold\n",
    "    ensemble.fit(X_train, y_train)\n",
    "\n",
    "    # Evaluate the performance of the ensemble model on the test set for this fold\n",
    "    y_pred = ensemble.predict(X_test)\n",
    "    y_preds.extend(y_pred)\n",
    "    y_tests.extend(y_test)\n",
    "    score = accuracy_score(y_test, y_pred)\n",
    "    scores.append(score)\n",
    "\n",
    "# Calculate the mean and standard deviation of the cross-validation scores\n",
    "mean_score = sum(scores) / len(scores)\n",
    "std_dev = np.std(scores)\n",
    "\n",
    "# Print the results\n",
    "print(\"Ensemble accuracy: %0.4f (+/- %0.2f)\" % (mean_score, std_dev * 2))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "84512982-5286-4ce4-ba6a-f9905992b9cd",
   "metadata": {},
   "source": [
    "### ADA BOOST"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9f6e9112-13ad-4c07-afd5-0e135639e17d",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from sklearn.model_selection import KFold\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.ensemble import RandomForestClassifier, AdaBoostClassifier,VotingClassifier\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "\n",
    "# Set up KFold cross-validation\n",
    "kf = KFold(n_splits=4, shuffle=True, random_state=42)\n",
    "\n",
    "# Initialize empty lists to store scores and predictions\n",
    "scores = []\n",
    "y_preds = []\n",
    "y_tests = []\n",
    "\n",
    "# Train the models and ensemble them\n",
    "rf = RandomForestClassifier(n_estimators=100)\n",
    "dt = DecisionTreeClassifier(random_state=42)\n",
    "ada = AdaBoostClassifier(estimator=dt, n_estimators=100)\n",
    "\n",
    "# Loop over the splits of the data and train/test the models\n",
    "for train_index, test_index in kf.split(X):\n",
    "    # Split the data into training and testing sets for this fold\n",
    "    X_train, X_test = X.iloc[train_index], X.iloc[test_index]\n",
    "    y_train, y_test = y.iloc[train_index], y.iloc[test_index]\n",
    "\n",
    "    # Fit the models to the training data for this fold\n",
    "    rf.fit(X_train, y_train)\n",
    "    dt.fit(X_train, y_train)\n",
    "    ada.fit(X_train, y_train)\n",
    "\n",
    "    # Combine the models into a voting classifier\n",
    "    ensemble = VotingClassifier(estimators=[('rf', rf), ('ada', ada)], voting='hard')\n",
    "    \n",
    "    # Fit the ensemble model to the training data for this fold\n",
    "    ensemble.fit(X_train, y_train)\n",
    "\n",
    "    # Evaluate the performance of the ensemble model on the test set for this fold\n",
    "    y_pred = ensemble.predict(X_test)\n",
    "    y_preds.extend(y_pred)\n",
    "    y_tests.extend(y_test)\n",
    "    score = accuracy_score(y_test, y_pred)\n",
    "    scores.append(score)\n",
    "\n",
    "# Calculate the mean and standard deviation of the cross-validation scores\n",
    "mean_score = sum(scores) / len(scores)\n",
    "std_dev = np.std(scores)\n",
    "\n",
    "# Print the results\n",
    "print(\"AdaBoost Ensemble accuracy: %0.4f (+/- %0.2f)\" % (mean_score, std_dev * 2))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
