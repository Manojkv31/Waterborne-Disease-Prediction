{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "531acde5-b7b5-4bd1-a55e-0a4111fd29a6",
   "metadata": {
    "tags": []
   },
   "source": [
    "# Typhoid"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1123466c",
   "metadata": {},
   "source": [
    "## Import libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d67704c0-c6c7-41dd-bd2d-3133b9756e4e",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import seaborn as sp\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.preprocessing import LabelEncoder, OneHotEncoder\n",
    "from sklearn.model_selection import KFold\n",
    "from imblearn.over_sampling import RandomOverSampler\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.metrics import roc_curve\n",
    "from sklearn.model_selection import train_test_split\n",
    "import pandas as pd\n",
    "from sklearn.utils import resample\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "from sklearn.svm import SVC\n",
    "import pickle as pk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "31c3c99c-179b-4762-923e-550855458ce7",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "typhoid = pd.read_csv('Dataset/final_typhoid.csv')\n",
    "typhoid.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3c289fbf-2cef-4d13-a501-ad7ea35e8144",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "typhoid.drop(['Unnamed: 0'], axis=1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "99a1b257-1d51-40d0-b993-190871857db2",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "typhoid.drop_duplicates()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f0a03612-b7d7-4fda-aee0-3b19fc7a640b",
   "metadata": {},
   "source": [
    "## CLEANING"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "31c71cc5-851a-4d66-830a-788aa7c167d0",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "typhoid['DISTRICT'].fillna(typhoid['DISTRICT'].mode()[0], inplace = True)\n",
    "typhoid['AGE'].fillna(typhoid['AGE'].median(), inplace = True)\n",
    "typhoid['REPORT_VERIFIED'].fillna(typhoid['REPORT_VERIFIED'].mode()[0], inplace = True)\n",
    "typhoid['TEHSIL'].fillna(typhoid['TEHSIL'].mode()[0], inplace = True)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1dfb886a-43a5-49c0-8435-552d28c28cff",
   "metadata": {},
   "source": [
    "## DATA BALANCING"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e1df8fef-dcdc-4592-ae13-8eca873103f5",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "#Class Distribution\n",
    "class_counts_typ = typhoid['RESULT_TEXT'].value_counts()\n",
    "\n",
    "class_distribution_typ =class_counts_typ / len(typhoid) *100\n",
    "\n",
    "print(class_distribution_typ)\n",
    "\n",
    "#plot a bar graph\n",
    "value = typhoid['RESULT_TEXT'].value_counts()\n",
    "\n",
    "plt.bar(value.index, value.values)\n",
    "\n",
    "plt.title('RESULT_TEXT')\n",
    "plt.xlabel('Result')\n",
    "plt.ylabel('Count')\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5fe8cbc6-b509-47a0-a0ed-97df63ab9d6b",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Resample data to handle imbalance\n",
    "x = typhoid.drop('RESULT_TEXT', axis = 1)\n",
    "y = typhoid['RESULT_TEXT']\n",
    "\n",
    "ros = RandomOverSampler(random_state=42)\n",
    "x_resampled, y_resampled = ros.fit_resample(x, y)\n",
    "\n",
    "#Concatenate the features and target into balanced datset\n",
    "balanced_data = pd.concat([x_resampled, y_resampled], axis=1)\n",
    "\n",
    "balanced_data.to_csv('new_copy2/Balanced_Typhoid.csv', index = False)\n",
    "\n",
    "Balanced_typhoid = pd.read_csv('new_copy2/Balanced_Typhoid.csv')\n",
    "\n",
    "#Class Distribution\n",
    "class_counts_typ = Balanced_typhoid['RESULT_TEXT'].value_counts()\n",
    "\n",
    "class_distribution_typ =class_counts_typ / len(Balanced_typhoid) *100\n",
    "\n",
    "print(class_distribution_typ)\n",
    "\n",
    "#plot a bar graph\n",
    "value = Balanced_typhoid['RESULT_TEXT'].value_counts()\n",
    "\n",
    "plt.bar(value.index, value.values)\n",
    "\n",
    "plt.title('RESULT_TEXT')\n",
    "plt.xlabel('Result')\n",
    "plt.ylabel('Count')\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4b48eab0-2ad7-4952-9d2b-cca81c84cf47",
   "metadata": {},
   "source": [
    "## DATA TRANSFORMATION"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "39083333-924a-4103-a975-c1abbf4d7457",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "typhoid.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dead00e2-025a-45cb-820f-c1f0e426b4ec",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "le = LabelEncoder()\n",
    "Balanced_typhoid[\"MRNO_encoded\"] = le.fit_transform(Balanced_typhoid[\"MRNO\"])\n",
    "Balanced_typhoid[\"RESULT_VALUE_encoded\"] = le.fit_transform(Balanced_typhoid[\"RESULT_VALUE\"])\n",
    "Balanced_typhoid[\"GENDER_encoded\"] = le.fit_transform(Balanced_typhoid[\"GENDER\"])\n",
    "Balanced_typhoid[\"REPORT_VERIFIED_encoded\"] = le.fit_transform(Balanced_typhoid[\"REPORT_VERIFIED\"])\n",
    "Balanced_typhoid[\"RESULT_TEXT_encoded\"] = le.fit_transform(Balanced_typhoid[\"RESULT_TEXT\"])\n",
    "# One-hot encode District and Tehsil\n",
    "ohe = OneHotEncoder(sparse=False)\n",
    "district_tehsil_encoded = ohe.fit_transform(Balanced_typhoid[[\"DISTRICT\", \"TEHSIL\"]])\n",
    "district_tehsil_encoded_df = pd.DataFrame(district_tehsil_encoded, columns=ohe.get_feature_names_out([\"DISTRICT\", \"TEHSIL\"]))\n",
    "\n",
    "# Combine the encoded columns with the original dataset\n",
    "new_df = pd.concat([Balanced_typhoid[\"MRNO_encoded\"], district_tehsil_encoded_df], axis=1)\n",
    "new_df[\"AGE\"] = Balanced_typhoid[\"AGE\"]\n",
    "new_df[\"RESULT_TEXT\"] = Balanced_typhoid[\"RESULT_TEXT_encoded\"]\n",
    "new_df[\"GENDER\"] = Balanced_typhoid[\"GENDER_encoded\"]\n",
    "new_df[\"RESULT_VALUE\"] = Balanced_typhoid[\"RESULT_VALUE_encoded\"]\n",
    "new_df[\"REPORT_VERIFIED\"] = Balanced_typhoid[\"REPORT_VERIFIED_encoded\"]\n",
    "new_df[\"CPT_ID\"] = Balanced_typhoid[\"CPT_ID\"]\n",
    "new_df[\"CPT_ID.1\"] = Balanced_typhoid[\"CPT_ID.1\"]\n",
    "# Save the new dataframe to a new CSV file\n",
    "new_df.to_csv('new_copy2/New_Typhoid.csv', index = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0f3eb50d-c0a7-4b92-94da-fb7ddbde5c4f",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "print(Balanced_typhoid['MRNO_encoded'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4d0a8874-5e17-4c79-afbf-3611122adf66",
   "metadata": {},
   "source": [
    "## NORMALISATION"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5057cf36-ca37-4abc-a90d-d8864939175c",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "value = Balanced_typhoid['AGE'].value_counts()\n",
    "\n",
    "plt.bar(value.index, value.values)\n",
    "\n",
    "plt.title('AGE')\n",
    "plt.xlabel('Age')\n",
    "plt.ylabel('Count')\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "008b3fc8-edca-40b6-9bc7-4e65443cf65c",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "Transformed_typhoid = pd.read_csv('new_copy2/New_Typhoid.csv', low_memory = False)\n",
    "# Column to be normalized\n",
    "column = ['AGE']\n",
    "\n",
    "Transformed_typhoid[column] = (Transformed_typhoid[column] - Transformed_typhoid[column].mean()) / Transformed_typhoid[column].std()\n",
    "\n",
    "# New .csv file with normalized data\n",
    "Transformed_typhoid.to_csv('new_copy2/Normalized_Typhoid.csv', index = False)# Column to be normalized\n",
    "column = ['AGE']\n",
    "\n",
    "Transformed_typhoid[column] = (Transformed_typhoid[column] - Transformed_typhoid[column].mean()) / Transformed_typhoid[column].std()\n",
    "\n",
    "# New .csv file with normalized data\n",
    "Transformed_typhoid.to_csv('new_copy2/Normalized_Typhoid.csv', index = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "042b924d-6b6d-4c5b-ac94-851dc818fb92",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "Normal_typhoid = pd.read_csv('new_copy2/Normalized_Typhoid.csv', low_memory = False)\n",
    "print(Normal_typhoid['AGE'].head())\n",
    "\n",
    "value = Normal_typhoid['AGE'].value_counts()\n",
    "\n",
    "plt.bar(value.index, value.values)\n",
    "\n",
    "plt.title('AGE')\n",
    "plt.xlabel('Age')\n",
    "plt.ylabel('Count')\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b2032f7c-9e29-45de-9e7d-9f247fa08314",
   "metadata": {},
   "outputs": [],
   "source": [
    "Normal_typhoid.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d5dc668c-0687-4d50-b44d-9f6d8d2f0320",
   "metadata": {},
   "outputs": [],
   "source": [
    "Normal_typhoid.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5fbc32ed-8e69-490c-bf6c-91c7b7e739c4",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "Normal_typhoid.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "88ef4a69-7e09-481d-9f33-07a377bf0f0d",
   "metadata": {},
   "source": [
    "## Random forest feature selection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b29cfe5f-cb97-43ad-a252-19e52e308b91",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Drop rows with missing data\n",
    "Normal_typhoid.dropna(inplace=True)\n",
    "\n",
    "# Split the data into feature matrix X and target vector y\n",
    "X = Normal_typhoid.drop('RESULT_TEXT', axis=1)\n",
    "y = Normal_typhoid['RESULT_TEXT']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3678a6f8-0547-404d-8252-8b808f28812e",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Use random forest to select the most important features\n",
    "rfc = RandomForestClassifier(n_estimators=100)\n",
    "rfc.fit(X, y)\n",
    "importance = rfc.feature_importances_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2c9dd048-f57b-4e43-87da-03e36b38153f",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# feat_imp=pd.Series(importance, index=X.columns)\n",
    "# feat_imp.nlargest(7).plot(kind=\"barh\")\n",
    "# print(feat_imp.nlargest(7))\n",
    "# plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "447fb36b-fd67-413b-8718-56dc18d73205",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a list of (feature name, importance) tuples and sort by importance\n",
    "features = list(zip(X.columns, importance))\n",
    "features.sort(key=lambda x: x[1], reverse=True)\n",
    "\n",
    "# Print the sorted list of feature importances\n",
    "for f in features:\n",
    "    print(f)\n",
    "\n",
    "\n",
    "# Select the top k features\n",
    "k = 7\n",
    "top_features = [f[0] for f in features[:k]]\n",
    "for f in top_features:\n",
    "    print(f)\n",
    "X = X[top_features]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3926fadd-ff38-440f-ab75-32e4a5d47efc",
   "metadata": {
    "tags": []
   },
   "source": [
    "### HISTOGRAM FOR FEATURE SELECTION"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bfc811cb-aae5-4423-91df-00be2e06a9bb",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "\n",
    "plt.title(\"Histogram for Feature selection importance\");\n",
    "plt.barh([x[0] for x in features],[x[1] for x in features])\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5e33532d-fb7b-499c-a987-20adda2cb8f7",
   "metadata": {
    "tags": []
   },
   "source": [
    "## RANDOM FOREST CLASSIFIER"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2ce07eeb-97f4-4d17-8559-50d1b0beb23e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train and evaluate the model using KFold\n",
    "kf = KFold(n_splits=10, shuffle=True, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "59f35a5b-4e91-44d1-8234-29864b64e5c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "accuracy_scores = []\n",
    "y_preds=[]\n",
    "y_tests=[]\n",
    "for train_index, test_index in kf.split(X):\n",
    "    # Split data into train and test sets for this fold\n",
    "    X_train, X_test = X.iloc[train_index], X.iloc[test_index]\n",
    "    y_train, y_test = y.iloc[train_index], y.iloc[test_index]\n",
    "\n",
    "    # Create and train the random forest classifier\n",
    "    rfc = RandomForestClassifier(n_estimators=100)\n",
    "    rfc.fit(X_train, y_train)\n",
    "\n",
    "    # Make predictions on the test set and calculate accuracy\n",
    "    y_pred = rfc.predict(X_test)\n",
    "    y_preds.extend(y_pred)\n",
    "    y_tests.extend(y_test)\n",
    "    accuracy = accuracy_score(y_test, y_pred)\n",
    "\n",
    "    # Add accuracy score to list\n",
    "    accuracy_scores.append(accuracy)\n",
    "pk.dump(rfc,open(\"model.pkl\",\"wb\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8bbd1354-5a45-4628-8689-61b880a84e94",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compute and print the mean accuracy score and standard deviation\n",
    "print(\"Accuracy- Random forest classifier: %0.2f (+/- %0.2f)\" % (np.mean(accuracy_scores), np.std(accuracy_scores) * 2))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "308a7ee9-32bd-4f62-aaf1-48a945be369a",
   "metadata": {},
   "source": [
    "### CONFUSION MATRIX FOR RF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c6cbba55-346b-4b9c-b39f-44155ed5c22e",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Assuming the true and predicted labels are stored in y_true and y_pred respectively\n",
    "cm = confusion_matrix(y_tests, y_preds)\n",
    "\n",
    "# Create a heatmap of the confusion matrix using Seaborn\n",
    "sp.heatmap(cm, annot=True, cmap=\"Blues\", fmt = 'd')\n",
    "\n",
    "# Add axis labels and a title\n",
    "plt.xlabel(\"Predicted labels\")\n",
    "plt.ylabel(\"True labels\")\n",
    "plt.title(\"Confusion Matrix for Random forest\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f707ef2f-8a7f-4990-b879-3ba3c91e123b",
   "metadata": {},
   "source": [
    "### ROC CURVE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c183c09b-a347-4bf6-8ff8-272f4d778b83",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# y_true: true labels, y_pred_prob: predicted probabilities\n",
    "fpr, tpr, thresholds = roc_curve(y_tests, y_preds)\n",
    "\n",
    "# plot ROC curve\n",
    "plt.plot(fpr, tpr)\n",
    "plt.plot([0, 1], [0, 1], linestyle='--')  # plot random curve\n",
    "plt.xlabel('False Positive Rate')\n",
    "plt.ylabel('True Positive Rate')\n",
    "plt.title('ROC Curve for Random Forest')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4a29968e-ceec-4c10-89f4-62393dc83323",
   "metadata": {
    "tags": []
   },
   "source": [
    "## KNN "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a1f1abf1-1867-429d-b94a-958201ee8357",
   "metadata": {},
   "outputs": [],
   "source": [
    "knn = KNeighborsClassifier(n_neighbors=5)\n",
    "\n",
    "kfold = KFold(n_splits=10, shuffle=True, random_state=42)\n",
    "accuracy_scores = []\n",
    "# Perform K-fold cross-validation and evaluate the model's performance\n",
    "y_true = []\n",
    "y_pred = []\n",
    "for train_idx, test_idx in kfold.split(X):\n",
    "    X_train, X_test = X.iloc[train_idx], X.iloc[test_idx]\n",
    "    y_train, y_test = y.iloc[train_idx], y.iloc[test_idx]\n",
    "    knn.fit(X_train, y_train)\n",
    "    y_true.extend(y_test)\n",
    "    y_pred.extend(knn.predict(X_test))\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "13490895-1023-4dae-94f3-918d482c76aa",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "accuracy = accuracy_score(y_true, y_pred)\n",
    "# Add accuracy score to list\n",
    "accuracy_scores.append(accuracy)\n",
    "# Compute and print the mean accuracy score and standard deviation\n",
    "print(\"Accuracy- KNN: %0.2f (+/- %0.2f)\" % (np.mean(accuracy_scores), np.std(accuracy_scores) * 2))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "368f9094-fca9-49f1-8d65-9b0f2131c57e",
   "metadata": {},
   "source": [
    "### CONFUSION MATRIX for KNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "db964c8c-8be2-4094-842c-5df966739429",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Assuming the true and predicted labels are stored in y_true and y_pred respectively\n",
    "cm = confusion_matrix(y_true, y_pred)\n",
    "# Create a heatmap of the confusion matrix using Seaborn\n",
    "sp.heatmap(cm, annot=True, cmap=\"Blues\", fmt=\"d\")\n",
    "\n",
    "# Add axis labels and a title\n",
    "plt.xlabel(\"Predicted labels\")\n",
    "plt.ylabel(\"True labels\")\n",
    "plt.title(\"Confusion Matrix for KNN\")\n",
    "\n",
    "# Show the plot\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2bd1292a-e016-46fa-a38a-ac1a502c79d3",
   "metadata": {},
   "source": [
    "### ROC curve"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5e7db510-17f8-42e6-830a-3cce8c6c877e",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# y_true: true labels, y_pred_prob: predicted probabilities\n",
    "fpr, tpr, thresholds = roc_curve(y_true, y_pred)\n",
    "\n",
    "# plot ROC curve\n",
    "plt.plot(fpr, tpr)\n",
    "plt.plot([0, 1], [0, 1], linestyle='--')  # plot random curve\n",
    "plt.xlabel('False Positive Rate')\n",
    "plt.ylabel('True Positive Rate')\n",
    "plt.title('ROC Curve for KNN')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0ad1a8c6-d4b8-4c06-bce2-8a1174c30920",
   "metadata": {
    "tags": []
   },
   "source": [
    "## DECISION TREE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "87c350fa-ac2a-4195-90ee-f2d05949c9df",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Initialize an empty list to store cross-validation scores\n",
    "scores = []\n",
    "y_pred=[]\n",
    "y_preds=[]\n",
    "y_tests=[]\n",
    "# Iterate over the splits of the data and train/test the model\n",
    "for train_index, test_index in kf.split(X):\n",
    "    # Split the data into training and testing sets for this fold\n",
    "    X_train, X_test = X.iloc[train_index], X.iloc[test_index]\n",
    "    y_train, y_test = y.iloc[train_index], y.iloc[test_index]\n",
    "    \n",
    "    # Train the decision tree classifier\n",
    "    dt = DecisionTreeClassifier(random_state=42)\n",
    "    dt.fit(X_train, y_train)\n",
    "    \n",
    "    # Evaluate the model's performance on the test set for this fold and store the score\n",
    "    y_pred = dt.predict(X_test)\n",
    "    y_preds.extend(y_pred)\n",
    "    y_tests.extend(y_test)\n",
    "    score = accuracy_score(y_test, y_pred)\n",
    "    scores.append(score)\n",
    "\n",
    "# Calculate the mean and standard deviation of the cross-validation scores\n",
    "mean_score = sum(scores) / len(scores)\n",
    "std_dev = np.std(scores)\n",
    "\n",
    "# Print the results\n",
    "print(\"Accuracy-Decision tree: %0.2f (+/- %0.2f)\" % (mean_score, std_dev * 2))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "95c790a6-5205-498b-a36a-9281712b81fc",
   "metadata": {
    "tags": []
   },
   "source": [
    "### CONFUSION MATRIX"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6422c75b-e6eb-42fc-aac5-ad166c101573",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Assuming the true and predicted labels are stored in y_true and y_pred respectively\n",
    "cm = confusion_matrix(y_tests, y_preds)\n",
    "np.set_printoptions(precision=3, suppress=True)\n",
    "# Create a heatmap of the confusion matrix using Seaborn\n",
    "sp.heatmap(cm, annot=True, cmap=\"Blues\",fmt=\"d\")\n",
    "\n",
    "# Add axis labels and a title\n",
    "plt.xlabel(\"Predicted labels\")\n",
    "plt.ylabel(\"True labels\")\n",
    "plt.title(\"Confusion Matrix for Decision tree\")\n",
    "\n",
    "# Show the plot\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9fa8e04c-c128-4dc7-80e2-591287673aa0",
   "metadata": {
    "tags": []
   },
   "source": [
    "### ROC CURVE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "47af36df-fbd8-4458-bc7c-fc1785f27cab",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# y_true: true labels, y_pred_prob: predicted probabilities\n",
    "fpr, tpr, thresholds = roc_curve(y_tests, y_preds)\n",
    "\n",
    "# plot ROC curve\n",
    "plt.plot(fpr, tpr)\n",
    "plt.plot([0, 1], [0, 1], linestyle='--')  # plot random curve\n",
    "plt.xlabel('False Positive Rate')\n",
    "plt.ylabel('True Positive Rate')\n",
    "plt.title('ROC Curve for Decision tree')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "16a5b48e-7354-4365-95d0-356d640c6006",
   "metadata": {
    "tags": []
   },
   "source": [
    "## LOGISITIC REGRESSION"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dc99de08-0731-47df-ac2b-8ca70e3144be",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Perform 10-fold cross validation using KFold method\n",
    "kf = KFold(n_splits=10, shuffle=True, random_state=42)\n",
    "lr = LogisticRegression(C=1)\n",
    "scores = []\n",
    "y_preds = []\n",
    "y_true = []\n",
    "for train_index, test_index in kf.split(X):\n",
    "    X_train, X_test = X.iloc[train_index], X.iloc[test_index]\n",
    "    y_train, y_test = y.iloc[train_index], y.iloc[test_index]\n",
    "    lr.fit(X_train, y_train)\n",
    "    y_pred = lr.predict(X_test)\n",
    "    y_preds.extend(y_pred)\n",
    "    y_true.extend(y_test)\n",
    "    scores.append(lr.score(X_test, y_test))\n",
    "\n",
    "# Calculate and print the cross-validation accuracy\n",
    "print(\"Accuracy- Logistic Regression: %0.2f (+/- %0.2f)\" % (np.mean(scores), np.std(scores) * 2))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7f820e3b-7451-45bf-829c-7e3ab6e04efc",
   "metadata": {
    "tags": []
   },
   "source": [
    "### CONFUSION MATRIX FOR LOGISTIC REGRESSION"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "393a2b5f-04ce-4597-a2d7-44646ffb962f",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Assuming the true and predicted labels are stored in y_true and y_pred respectively\n",
    "cm = confusion_matrix(y_true, y_preds)\n",
    "np.set_printoptions(precision=3, suppress=True)\n",
    "# Create a heatmap of the confusion matrix using Seaborn\n",
    "sp.heatmap(cm, annot=True, cmap=\"Blues\",fmt=\"d\")\n",
    "\n",
    "# Add axis labels and a title\n",
    "plt.xlabel(\"Predicted labels\")\n",
    "plt.ylabel(\"True labels\")\n",
    "plt.title(\"Confusion Matrix for Logistic Regression\")\n",
    "\n",
    "# Show the plot\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8478750c-e281-42b9-b73b-2383da6308c0",
   "metadata": {
    "tags": []
   },
   "source": [
    "### ROC curve for Logistic Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d53bd676-b89f-45fd-947c-ed484726e771",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# y_true: true labels, y_pred_prob: predicted probabilities\n",
    "fpr, tpr, thresholds = roc_curve(y_test, y_pred)\n",
    "\n",
    "# plot ROC curve\n",
    "plt.plot(fpr, tpr)\n",
    "plt.plot([0, 1], [0, 1], linestyle='--')  # plot random curve\n",
    "plt.xlabel('False Positive Rate')\n",
    "plt.ylabel('True Positive Rate')\n",
    "plt.title('ROC Curve for Logisitic Regression')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1f0e1967-0196-4d9d-81d7-940a2d91f335",
   "metadata": {
    "tags": []
   },
   "source": [
    "## SUPPORT VECTOR MACHINE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "60b6c328-92a0-433a-a457-bbf02b35b204",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "y_pred=[]\n",
    "y_preds=[]\n",
    "y_true=[]\n",
    "# Define the desired sample size for the reduced dataset\n",
    "sample_size = 5000\n",
    "\n",
    "# Initialize SVM classifier with default hyperparameters\n",
    "svm = SVC()\n",
    "\n",
    "# Use stratified k-fold cross-validation to evaluate classifier performance\n",
    "skf = StratifiedKFold(n_splits=10, random_state=42, shuffle=True)\n",
    "scores = []\n",
    "\n",
    "# Loop over each fold and perform stratified sampling on the training set\n",
    "for train_index, test_index in skf.split(X,y):\n",
    "    \n",
    "    X_train, X_test = X.iloc[train_index], X.iloc[test_index]\n",
    "    y_train, y_test = y.iloc[train_index], y.iloc[test_index]\n",
    "    \n",
    "    # Use stratified sampling to select the desired number of samples from each class\n",
    "    X_sampled, y_sampled = resample(X_train, y_train, n_samples=sample_size, stratify=y_train, random_state=42)\n",
    "\n",
    "    # Fit SVM classifier on the reduced dataset and evaluate performance on the test set\n",
    "    svm.fit(X_sampled, y_sampled)\n",
    "    y_pred = svm.predict(X_test)\n",
    "    y_preds.extend(y_pred)\n",
    "    y_true.extend(y_test)\n",
    "    scores.append(svm.score(X_test,y_test))\n",
    "\n",
    "# Print the average classification accuracy over all folds\n",
    "print(\"Accuracy- SVM: {:.2f}\".format(sum(scores)/len(scores)))\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6a43317e-9383-4baa-93ae-e70f7ff13c39",
   "metadata": {},
   "source": [
    "### CONFUSION MATRIX for SVM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6ea6804f-912d-4d9d-a23a-eafb5350e873",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Assuming the true and predicted labels are stored in y_true and y_pred respectively\n",
    "cm = confusion_matrix(y_true, y_preds)\n",
    "np.set_printoptions(precision=3, suppress=True)\n",
    "# Create a heatmap of the confusion matrix using Seaborn\n",
    "sp.heatmap(cm, annot=True, cmap=\"Blues\",fmt=\"d\")\n",
    "\n",
    "# Add axis labels and a title\n",
    "plt.xlabel(\"Predicted labels\")\n",
    "plt.ylabel(\"True labels\")\n",
    "plt.title(\"Confusion Matrix for SVM \")\n",
    "\n",
    "# Show the plot\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "18526efd-f731-4a59-801e-da4ab2c1d8b4",
   "metadata": {},
   "source": [
    "### ROC curve for SVM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "89d0b4d8-ee12-432b-9972-0fe1986fe5e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# y_true: true labels, y_pred_prob: predicted probabilities\n",
    "fpr, tpr, thresholds = roc_curve(y_test, y_pred)\n",
    "\n",
    "# plot ROC curve\n",
    "plt.plot(fpr, tpr)\n",
    "plt.plot([0, 1], [0, 1], linestyle='--')  # plot random curve\n",
    "plt.xlabel('False Positive Rate')\n",
    "plt.ylabel('True Positive Rate')\n",
    "plt.title('ROC Curve for SVM')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "72add9fc-e032-4162-bd21-c0a6edbea50b",
   "metadata": {},
   "source": [
    "## ENSEMBLE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d29b6f2d-0179-4c66-b170-4cbd35182737",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from sklearn.model_selection import KFold\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.ensemble import RandomForestClassifier, VotingClassifier\n",
    "\n",
    "# Set up KFold cross-validation\n",
    "kf = KFold(n_splits=10, shuffle=True, random_state=42)\n",
    "\n",
    "# Initialize empty lists to store scores and predictions\n",
    "scores = []\n",
    "y_preds = []\n",
    "y_tests = []\n",
    "\n",
    "# Train the models and ensemble them\n",
    "rf = RandomForestClassifier(n_estimators=100)\n",
    "dt = DecisionTreeClassifier(random_state=42)\n",
    "lr=LogisticRegression(C=1)\n",
    "ensemble = VotingClassifier(estimators=[('rf', rf), ('dt', dt), ('lr', lr)], voting='hard')\n",
    "\n",
    "# Loop over the splits of the data and train/test the models\n",
    "for train_index, test_index in kf.split(X):\n",
    "    # Split the data into training and testing sets for this fold\n",
    "    X_train, X_test = X.iloc[train_index], X.iloc[test_index]\n",
    "    y_train, y_test = y.iloc[train_index], y.iloc[test_index]\n",
    "\n",
    "    # Fit the models to the training data for this fold\n",
    "    rf.fit(X_train, y_train)\n",
    "    dt.fit(X_train, y_train)\n",
    "    lr.fit(X_train, y_train)\n",
    "\n",
    "    # Fit the ensemble model to the training data for this fold\n",
    "    ensemble.fit(X_train, y_train)\n",
    "\n",
    "    # Evaluate the performance of the ensemble model on the test set for this fold\n",
    "    y_pred = ensemble.predict(X_test)\n",
    "    y_preds.extend(y_pred)\n",
    "    y_tests.extend(y_test)\n",
    "    score = accuracy_score(y_test, y_pred)\n",
    "    scores.append(score)\n",
    "\n",
    "# Calculate the mean and standard deviation of the cross-validation scores\n",
    "mean_score = sum(scores) / len(scores)\n",
    "std_dev = np.std(scores)\n",
    "\n",
    "# Print the results\n",
    "print(\"Ensemble accuracy: %0.4f (+/- %0.2f)\" % (mean_score, std_dev * 2))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5ac4fe1d-49e5-4a97-8aa2-63a4cb0d03e3",
   "metadata": {},
   "source": [
    "### ADABOOSTING"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "514d548a-38fd-42b3-8ff9-9a9a53fb8f1b",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import KFold\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.ensemble import RandomForestClassifier, AdaBoostClassifier,VotingClassifier\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "\n",
    "# Set up KFold cross-validation\n",
    "kf = KFold(n_splits=4, shuffle=True, random_state=42)\n",
    "\n",
    "# Initialize empty lists to store scores and predictions\n",
    "scores = []\n",
    "y_preds = []\n",
    "y_tests = []\n",
    "\n",
    "# Train the models and ensemble them\n",
    "rf = RandomForestClassifier(n_estimators=100)\n",
    "dt = DecisionTreeClassifier(random_state=42)\n",
    "ada = AdaBoostClassifier(estimator=dt, n_estimators=100)\n",
    "\n",
    "# Loop over the splits of the data and train/test the models\n",
    "for train_index, test_index in kf.split(X):\n",
    "    # Split the data into training and testing sets for this fold\n",
    "    X_train, X_test = X.iloc[train_index], X.iloc[test_index]\n",
    "    y_train, y_test = y.iloc[train_index], y.iloc[test_index]\n",
    "\n",
    "    # Fit the models to the training data for this fold\n",
    "    rf.fit(X_train, y_train)\n",
    "    dt.fit(X_train, y_train)\n",
    "    ada.fit(X_train, y_train)\n",
    "\n",
    "    # Combine the models into a voting classifier\n",
    "    ensemble = VotingClassifier(estimators=[('rf', rf), ('ada', ada)], voting='hard')\n",
    "    \n",
    "    # Fit the ensemble model to the training data for this fold\n",
    "    ensemble.fit(X_train, y_train)\n",
    "\n",
    "    # Evaluate the performance of the ensemble model on the test set for this fold\n",
    "    y_pred = ensemble.predict(X_test)\n",
    "    y_preds.extend(y_pred)\n",
    "    y_tests.extend(y_test)\n",
    "    score = accuracy_score(y_test, y_pred)\n",
    "    scores.append(score)\n",
    "\n",
    "# Calculate the mean and standard deviation of the cross-validation scores\n",
    "mean_score = sum(scores) / len(scores)\n",
    "std_dev = np.std(scores)\n",
    "\n",
    "# Print the results\n",
    "print(\"AdaBoost Ensemble accuracy: %0.4f (+/- %0.2f)\" % (mean_score, std_dev * 2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "43cc15d5-2f7c-43ed-b374-2436cf564a49",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
